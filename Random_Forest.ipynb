{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2cb4a9-dabf-44e1-ba93-13aa1e47ef0e",
   "metadata": {},
   "source": [
    "## Project: Implementation of Random Forest Classifier Algorithm from Scratch\n",
    "\n",
    "### Overview:\n",
    "\n",
    "Developed a random forest classifier from the ground up without relying on external machine learning libraries. The goal was to build a robust ensemble learning model and gain a deeper understanding of the algorithm.\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "- Created DecisionTree class to construct single decision trees using information gain criteria for node splitting. In addition, methods for predicting, and fitting were included.\n",
    "\n",
    "- BootstrapSampling function randomly draws samples with replacement to create training data for individual trees. \n",
    "\n",
    "- RandomForest class initializes hyperparameters, and stores fitted (trained) trees in a list.\n",
    "\n",
    "- Fit method grows each tree on a bootstrapped sample to completion using the DecisionTree class. \n",
    "\n",
    "- Predict aggregates predictions from all trees and returns the majority vote via a plurality calculation.\n",
    "\n",
    "\n",
    "### Evaluation:  \n",
    "\n",
    "- Tested on breast cancer dataset from scikit-learn with 10-fold cross-validation.\n",
    "\n",
    "- Achieved well above 90% accuracy demonstrating the efficacy of the random forest approach.\n",
    "\n",
    "- Parameters tuning of max_depth and n_estimators (number of trees) were utilized to optimize performance.\n",
    "\n",
    "### Skills: \n",
    "Algorithm design, NumPy, Classification, Ensemble methods, Scikit-learn datasets. \n",
    "\n",
    "#### Outcome: \n",
    "Successful implementation of Random Forest from scratch establishing the core understanding of the algorithm. The thorough evaluation showed the viability of the approach for real-world problems. \n",
    "\n",
    "On the whole, this project provides an example of my skills in algorithm design and implementation, classification modeling, and hands-on experience with standard ML techniques and datasets. It is indeed worth mentioning that the from-scratch approach strengthened conceptual understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd04e8-7d21-42be-bc93-96f82f31290f",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ad8a8d-d313-4377-a404-39654c35c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "814e4ffc-612e-4f85-a03c-308abc17b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(X, y):\n",
    "    N = X.shape[0]\n",
    "    idxs = np.random.choice(N, N, replace=True)\n",
    "    return X[idxs], y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "592d7c70-5c02-4eea-8197-452ec4ac065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_label(y):\n",
    "    return Counter(y).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "277a44d4-9574-41e0-b837-c39012fda2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    Ps = hist / len(y)\n",
    "    return -np.sum([p*np.log2(p) for p in Ps if p>0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2074e-368d-424f-87a0-cd23e1bb0187",
   "metadata": {},
   "source": [
    "## Creating The Architecture of Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "822f425c-542e-4e57-a4ef-17e7d8ead349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0a790-e44c-496a-8d37-c29fde59fda7",
   "metadata": {},
   "source": [
    "## Creating The Architecture of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0009540-7ce9-447d-b3db-bcc5d2b81e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_sample_split=2, max_depth=100, n_features=None):\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(self.n_features, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        N, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # checking the stopping criteria:\n",
    "        if(depth >= self.max_depth\n",
    "          or N < self.min_sample_split\n",
    "          or n_labels == 1):\n",
    "            leaf_value = self._most_common(y)\n",
    "            return Node(value = leaf_value)\n",
    "\n",
    "        feature_idxs = np.random.choice(n_features, self.n_features, replace=False)\n",
    "        \n",
    "        best_feature, best_threshold = self._best_criteria(X, y, feature_idxs)\n",
    "        \n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], y, best_threshold)\n",
    "        \n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "\n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feature_idxs):\n",
    "        split_feature, split_threshold = None, None\n",
    "        best_gain = -1\n",
    "        for idx in feature_idxs:\n",
    "            X_column = X[:, idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_feature = idx\n",
    "                    split_threshold = threshold\n",
    "        return split_feature, split_threshold\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        entropy_parent = entropy(y)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X_column, y, threshold)\n",
    "\n",
    "        entropy_child = (len(left_idxs) / len(y))*(entropy(y[left_idxs])) + (len(right_idxs) / len(y))*(entropy(y[right_idxs]))\n",
    "\n",
    "        return entropy_parent - entropy_child\n",
    "\n",
    "    def _split(self, X_column, y, threshold):\n",
    "        left = np.argwhere(X_column <= threshold).flatten()\n",
    "        right = np.argwhere(X_column > threshold).flatten()\n",
    "        return left, right\n",
    "                    \n",
    "    def _most_common(self, y):\n",
    "        most_common = Counter(y).most_common(1)\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b32cb-bb73-4ec4-ba33-885b8572cab8",
   "metadata": {},
   "source": [
    "## Creating The Structure of Random Forest Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cdf26e1-5107-43f5-aece-d39a3ac1a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, min_sample_split=2, max_depth=100, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(min_sample_split=self.min_sample_split, max_depth=self.max_depth)\n",
    "\n",
    "            X_sample, y_sample = bootstrap_sample(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        trees_preds = [tree.predict(X) for tree in self.trees]\n",
    "        trees_preds = np.swapaxes(trees_preds, 0, 1)\n",
    "        y_pred = [most_common_label(trees_pred) for trees_pred in trees_preds]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf00ba-a39c-4194-b2d1-1663ddab9e3e",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d48742cc-12f5-4eba-8410-d7a29031985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c401bb9-002d-4941-ad3c-ce15deda0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2efa3a-05d9-41ad-8559-e994d4157c6e",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1592c6d-0578-484a-b71f-f812016c1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa7f353-dfc6-490d-95f4-411055470f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d375c21-b79d-4e55-abdf-d0b8f984fdbd",
   "metadata": {},
   "source": [
    "### Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccd38ba1-55a1-4851-be98-393eb8e24d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForest(n_trees=3, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f478f5-95e6-49ba-9592-9b1774ae2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433aff3-2703-4874-a7da-23f464b89b0b",
   "metadata": {},
   "source": [
    "### Predicting the Test set results & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0e0ef7e-2167-4c1b-849a-1bfe71708410",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b65fbf34-caf3-4793-8e16-dfb22e753f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2c31504-8fe1-40d8-8b56-2688bb9acd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e7fc629-ad4b-43b9-9e3e-458a2ba5a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
